{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from SOM_plus_clustering.som import SOM\n",
    "from SOM_plus_clustering.som import kmeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151700</td>\n",
       "      <td>351102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155799</td>\n",
       "      <td>354358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142857</td>\n",
       "      <td>352716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152726</td>\n",
       "      <td>349144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151008</td>\n",
       "      <td>349692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1\n",
       "0  151700  351102\n",
       "1  155799  354358\n",
       "2  142857  352716\n",
       "3  152726  349144\n",
       "4  151008  349692"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset to be tested in clustering\n",
    "df = pd.read_csv('unbalance.txt', sep=\" \", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39662943, 0.91797881],\n",
       "       [0.40248208, 0.91542786],\n",
       "       [0.37539822, 0.92686363],\n",
       "       ...,\n",
       "       [0.81075656, 0.58538346],\n",
       "       [0.80687506, 0.59072214],\n",
       "       [0.79820051, 0.60239186]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.values\n",
    "preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(X: np.ndarray, y:np.ndarray) -> float or None:\n",
    "    \"\"\"\n",
    "    Get the value of shilhouette score with existed label.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Values of input variables of data.\n",
    "        y (np.ndarray): Prediction value of data.\n",
    "\n",
    "    Returns:\n",
    "        float: If there is only 1 label, return None, else return the silhouette score\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return silhouette_score(X,y)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clustering_method(X: np.ndarray, total_trial: int, som_max_iteration:int, som_lr: float, som_nr:int, epoch:int, kmeans_total_cluster:int, som_m:int, som_n:int, path:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Collects silhouette score of kmeans and SOM method with different initiator method.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Values of test dataset.\n",
    "        total_trial (int): Number of iteration for each clustering.\n",
    "        som_max_iteration (int): Maximum iteration for self organizing matrix.\n",
    "        som_lr (float): Value of learning rate (alpha) of Self Organzing Matrix.\n",
    "        som_nr (int): Value of radius (gamma) of Self Organizing Matrix.\n",
    "        epoch (int): Number of training iteration.\n",
    "        kmeans_total_cluster (int): Total number of center that initiated in kmeans.\n",
    "        som_m (int): Height of matrix in Self Organizing Matrix.\n",
    "        som_n (int): Width of matrix in Self Organizing Matrix.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table of silhouette score for each method.\n",
    "    \"\"\"\n",
    "    list_data = list()\n",
    "    for i in range(total_trial):\n",
    "        \"\"\"\n",
    "        model1 = kmeans(n_clusters=kmeans_total_cluster, method=\"random\")\n",
    "        model1.fit(X, epochs=epoch)\n",
    "        \n",
    "        model2 = kmeans(n_clusters=kmeans_total_cluster, method=\"kde\")\n",
    "        model2.fit(X, epochs=epoch)\n",
    "        \n",
    "        model3 = kmeans(n_clusters=kmeans_total_cluster, method=\"kmeans++\")\n",
    "        model3.fit(X, epochs=epoch)\n",
    "        \n",
    "        model4 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"random\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model4.fit(X, epoch=epoch)\n",
    "        \n",
    "        model5 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kmeans\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model5.fit(X,epoch=epoch)\n",
    "        \n",
    "        model6 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kde_kmeans\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model6.fit(X, epoch=epoch)\n",
    "        \n",
    "        model7 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kmeans++\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model7.fit(X, epoch=epoch)\n",
    "        \n",
    "        model8 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"SOM++\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model8.fit(X, epoch=epoch)\n",
    "        \n",
    "        model9 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kde\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model9.fit(X, epoch=epoch)\n",
    "        \"\"\"\n",
    "        model1 = kmeans(n_clusters=kmeans_total_cluster, method=\"random\")\n",
    "        model2 = kmeans(n_clusters=kmeans_total_cluster, method=\"kde\")\n",
    "        model3 = kmeans(n_clusters=kmeans_total_cluster, method=\"kmeans++\")\n",
    "        model4 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"random\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model5 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kmeans\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model6 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kde_kmeans\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model7 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kmeans++\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model8 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"SOM++\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        model9 = SOM(m = som_m, n = som_n, dim = X.shape[1], initiate_method = \"kde\", max_iter = som_max_iteration, learning_rate = som_lr, neighbour_rad = som_nr)\n",
    "        print(\"trial number\", i)\n",
    "        \n",
    "        # multi processing part 1 - predict the model\n",
    "        p1 = multiprocessing.Process(target=model1.fit(X, epochs=epoch))\n",
    "        p2 = multiprocessing.Process(target=model2.fit(X, epochs=epoch))\n",
    "        p3 = multiprocessing.Process(target=model3.fit(X, epochs=epoch))\n",
    "        p4 = multiprocessing.Process(target=model4.fit(X, epoch=epoch))\n",
    "        p5 = multiprocessing.Process(target=model5.fit(X, epoch=epoch))\n",
    "        p6 = multiprocessing.Process(target=model6.fit(X, epoch=epoch))\n",
    "        p7 = multiprocessing.Process(target=model7.fit(X, epoch=epoch))\n",
    "        p8 = multiprocessing.Process(target=model8.fit(X, epoch=epoch))\n",
    "        p9 = multiprocessing.Process(target=model9.fit(X, epoch=epoch))\n",
    "        \n",
    "        p1.start()\n",
    "        p2.start()\n",
    "        p3.start()\n",
    "        p4.start()\n",
    "        p5.start()\n",
    "        p6.start()\n",
    "        p7.start()\n",
    "        p8.start()\n",
    "        p9.start()\n",
    "        \n",
    "        p1.join()\n",
    "        p2.join()\n",
    "        p3.join()\n",
    "        p4.join()\n",
    "        p5.join()\n",
    "        p6.join()\n",
    "        p7.join()\n",
    "        p8.join()\n",
    "        p9.join()\n",
    "        \n",
    "        print(\"finnised trained the models\")\n",
    "        # get the value of silhouette score\n",
    "        ss1 = get_ss(X,model1.predict(X))\n",
    "        ss2 = get_ss(X,model2.predict(X))\n",
    "        ss3 = get_ss(X,model3.predict(X))\n",
    "        ss4 = get_ss(X,model4.predict(X))\n",
    "        ss5 = get_ss(X,model5.predict(X))\n",
    "        ss6 = get_ss(X,model6.predict(X))\n",
    "        ss7 = get_ss(X,model7.predict(X))\n",
    "        ss8 = get_ss(X,model8.predict(X))\n",
    "        ss9 = get_ss(X,model9.predict(X))\n",
    "        \n",
    "        print(\"finised evaluated the models\")\n",
    "        \n",
    "        list_shs = [ss1, ss2, ss3, ss4, ss5, ss6, ss7, ss8, ss9]\n",
    "        list_data.append(list_shs)\n",
    "        print(\"saving data\")\n",
    "        data_table = pd.DataFrame(list_data, columns=[\"random kmeans\", \"kde kmeans\", \"kmeans++\", \"random SOM\", \"kmeans SOM\", \"kde kmeans SOM\", \"kmeans++ SOM\", \"SOM++\", \"kde SOM\"])\n",
    "        data_table.to_csv(path, index=False)\n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number 0\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 1\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 2\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 3\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 4\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 5\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 6\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 7\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 8\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 9\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 10\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 11\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 12\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 13\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 14\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 15\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 16\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 17\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 18\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 19\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 20\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 21\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 22\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 23\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 24\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 25\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 26\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 27\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 28\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 29\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 30\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 31\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 32\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 33\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 34\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 35\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 36\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 37\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 38\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 39\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 40\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 41\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 42\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 43\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 44\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 45\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 46\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 47\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 48\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 49\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 50\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 51\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 52\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 53\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 54\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 55\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 56\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 57\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 58\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 59\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 60\n",
      "finnised trained the models\n",
      "finnised evaluated the models\n",
      "saving data\n",
      "trial number 61\n"
     ]
    }
   ],
   "source": [
    "# extract value from dataframe\n",
    "test_values = df.values\n",
    "\n",
    "# normalize the data\n",
    "test_values = preprocessing.normalize(X)\n",
    "\n",
    "# create a table of silhouette score\n",
    "test_clustering_method(X = test_values, \n",
    "                                total_trial = 100, \n",
    "                                som_max_iteration = 500, \n",
    "                                som_lr = 0.5, \n",
    "                                som_nr = 4, \n",
    "                                epoch = 2, \n",
    "                                kmeans_total_cluster = 8, \n",
    "                                som_m = 4, \n",
    "                                som_n = 2,\n",
    "                                path=\"Datas/silhouette_score_data_dummy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
